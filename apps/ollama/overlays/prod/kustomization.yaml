# From https://github.com/truecharts/charts/blob/master/charts/stable/ollama/values.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
  - ../../base
  - ingress-route.yaml

helmCharts:
  - name: ollama
    repo: oci://tccr.io/truecharts
    releaseName: ollama
    namespace: llm
    version: 7.13.16
    includeCRDs: true
    valuesInline:
      TZ: America/Los_Angeles
      workload:
        main:
          podSpec:
            containers:
              main:
                resources:
                  limits:
                    cpu: "3"
                    memory: 26Gi
                    nvidia.com/gpu: 2
                  requests:
                    cpu: 500m
                    memory: 2Gi
                env:
                  OLLAMA_FLASH_ATTENTION: "1"
                  OLLAMA_NUM_THREADS: "4"
                  OLLAMA_MAX_LOADED_MODELS: "2"
                  OLLAMA_DEBUG: "true"
                  NVIDIA_VISIBLE_DEVICES: all
            runtimeClassName: nvidia
            tolerations:
              - key: nvidia.com/gpu
                operator: Exists
                effect: NoSchedule
      persistence:
        config:
          enabled: true
          retain: true
          storageClass: "ceph-block"
          accessMode: ReadWriteOnce
          size: 160Gi
        data:
          enabled: true
          retain: true
          storageClass: "ceph-block"
          accessMode: ReadWriteOnce
      portal:
        open:
          enabled: false
